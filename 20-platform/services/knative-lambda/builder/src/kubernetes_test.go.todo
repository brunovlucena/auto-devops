package main

import (
	"context"
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"testing"
	"time"

	"github.com/aws/aws-sdk-go-v2/aws"
	"github.com/aws/aws-sdk-go-v2/config"
	"github.com/aws/aws-sdk-go-v2/service/eks"
	batchv1 "k8s.io/api/batch/v1"
	corev1 "k8s.io/api/core/v1"
	"k8s.io/apimachinery/pkg/api/resource"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/apis/meta/v1/unstructured"
	"k8s.io/apimachinery/pkg/runtime/schema"
	"k8s.io/apimachinery/pkg/util/wait"
	"k8s.io/client-go/kubernetes"
	"k8s.io/client-go/rest"
	"sigs.k8s.io/aws-iam-authenticator/pkg/token"
)

// EKSTestConfig holds configuration for EKS integration tests
type EKSTestConfig struct {
	ClusterName string
	Region      string
	Namespace   string
	Timeout     time.Duration
	SkipCleanup bool
}

// getEKSTestConfig returns EKS test configuration from environment variables
func getEKSTestConfig() *EKSTestConfig {
	config := &EKSTestConfig{
		ClusterName: os.Getenv("EKS_CLUSTER_NAME"),
		Region:      os.Getenv("AWS_REGION"),
		Namespace:   os.Getenv("EKS_TEST_NAMESPACE"),
		Timeout:     5 * time.Minute,
		SkipCleanup: os.Getenv("EKS_SKIP_CLEANUP") == "true",
	}

	if config.Region == "" {
		config.Region = "us-east-1"
	}
	if config.Namespace == "" {
		config.Namespace = "knative-lambda-test"
	}

	return config
}

// skipEKSTests returns true if EKS tests should be skipped
func skipEKSTests(t *testing.T) bool {
	if os.Getenv("SKIP_EKS_TESTS") == "true" {
		t.Skip("EKS tests skipped via SKIP_EKS_TESTS environment variable")
		return true
	}

	config := getEKSTestConfig()
	if config.ClusterName == "" {
		t.Skip("EKS tests skipped - EKS_CLUSTER_NAME not set")
		return true
	}

	return false
}

// getEKSKubernetesConfig creates a Kubernetes config for EKS cluster
func getEKSKubernetesConfig(clusterName, region string) (*rest.Config, error) {
	// Load AWS config
	cfg, err := config.LoadDefaultConfig(context.TODO(), config.WithRegion(region))
	if err != nil {
		return nil, fmt.Errorf("failed to load AWS config: %w", err)
	}

	// Create EKS client
	eksClient := eks.NewFromConfig(cfg)

	// Get cluster info
	clusterOutput, err := eksClient.DescribeCluster(context.TODO(), &eks.DescribeClusterInput{
		Name: aws.String(clusterName),
	})
	if err != nil {
		return nil, fmt.Errorf("failed to describe EKS cluster: %w", err)
	}

	cluster := clusterOutput.Cluster
	if cluster.Endpoint == nil || cluster.CertificateAuthority == nil {
		return nil, fmt.Errorf("invalid cluster configuration")
	}

	// Generate token for authentication
	gen, err := token.NewGenerator(false, false)
	if err != nil {
		return nil, fmt.Errorf("failed to create token generator: %w", err)
	}

	opts := &token.GetTokenOptions{
		ClusterID: clusterName,
		Region:    region,
	}

	tok, err := gen.GetWithOptions(opts)
	if err != nil {
		return nil, fmt.Errorf("failed to get token: %w", err)
	}

	// Create Kubernetes config
	kubeConfig := &rest.Config{
		Host:        *cluster.Endpoint,
		BearerToken: tok.Token,
		TLSClientConfig: rest.TLSClientConfig{
			CAData: []byte(*cluster.CertificateAuthority.Data),
		},
		Timeout: 60 * time.Second,
	}

	return kubeConfig, nil
}

// ensureNamespace creates the test namespace if it doesn't exist
func ensureNamespace(ctx context.Context, clientset *kubernetes.Clientset, namespace string) error {
	_, err := clientset.CoreV1().Namespaces().Get(ctx, namespace, metav1.GetOptions{})
	if err == nil {
		return nil // Namespace already exists
	}

	// Create namespace
	ns := &corev1.Namespace{
		ObjectMeta: metav1.ObjectMeta{
			Name: namespace,
			Labels: map[string]string{
				"created-by": "knative-lambda-test",
				"test-run":   fmt.Sprintf("%d", time.Now().Unix()),
			},
		},
	}

	_, err = clientset.CoreV1().Namespaces().Create(ctx, ns, metav1.CreateOptions{})
	if err != nil {
		return fmt.Errorf("failed to create namespace %s: %w", namespace, err)
	}

	return nil
}

// cleanupTestResources removes test resources from the cluster
func cleanupTestResources(ctx context.Context, clientset *kubernetes.Clientset, namespace string) error {
	// Delete all jobs in the namespace
	err := clientset.BatchV1().Jobs(namespace).DeleteCollection(ctx, metav1.DeleteOptions{}, metav1.ListOptions{
		LabelSelector: "created-by=knative-lambda-test",
	})
	if err != nil {
		return fmt.Errorf("failed to delete jobs: %w", err)
	}

	// Delete all configmaps in the namespace
	err = clientset.CoreV1().ConfigMaps(namespace).DeleteCollection(ctx, metav1.DeleteOptions{}, metav1.ListOptions{
		LabelSelector: "created-by=knative-lambda-test",
	})
	if err != nil {
		return fmt.Errorf("failed to delete configmaps: %w", err)
	}

	return nil
}

// TestEKSConnection tests connection to EKS cluster
func TestEKSConnection(t *testing.T) {
	if skipEKSTests(t) {
		return
	}

	config := getEKSTestConfig()

	t.Run("connect to EKS cluster", func(t *testing.T) {
		kubeConfig, err := getEKSKubernetesConfig(config.ClusterName, config.Region)
		if err != nil {
			t.Fatalf("Failed to get EKS Kubernetes config: %v", err)
		}

		clientset, err := kubernetes.NewForConfig(kubeConfig)
		if err != nil {
			t.Fatalf("Failed to create Kubernetes clientset: %v", err)
		}

		ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
		defer cancel()

		// Test connection by listing namespaces
		namespaces, err := clientset.CoreV1().Namespaces().List(ctx, metav1.ListOptions{})
		if err != nil {
			t.Fatalf("Failed to list namespaces: %v", err)
		}

		t.Logf("Successfully connected to EKS cluster %s, found %d namespaces", config.ClusterName, len(namespaces.Items))
	})
}

// TestEKSDeployJob tests deploying a Kaniko build job to EKS
func TestEKSDeployJob(t *testing.T) {
	if skipEKSTests(t) {
		return
	}

	config := getEKSTestConfig()

	kubeConfig, err := getEKSKubernetesConfig(config.ClusterName, config.Region)
	if err != nil {
		t.Fatalf("Failed to get EKS Kubernetes config: %v", err)
	}

	clientset, err := kubernetes.NewForConfig(kubeConfig)
	if err != nil {
		t.Fatalf("Failed to create Kubernetes clientset: %v", err)
	}

	ctx, cancel := context.WithTimeout(context.Background(), config.Timeout)
	defer cancel()

	// Ensure test namespace exists
	err = ensureNamespace(ctx, clientset, config.Namespace)
	if err != nil {
		t.Fatalf("Failed to ensure namespace: %v", err)
	}

	// Cleanup function
	cleanup := func() {
		if !config.SkipCleanup {
			cleanupCtx, cleanupCancel := context.WithTimeout(context.Background(), 30*time.Second)
			defer cleanupCancel()
			if err := cleanupTestResources(cleanupCtx, clientset, config.Namespace); err != nil {
				t.Logf("Warning: cleanup failed: %v", err)
			}
		}
	}
	defer cleanup()

	t.Run("deploy kaniko build job", func(t *testing.T) {
		// Create a test job
		jobName := fmt.Sprintf("test-kaniko-job-%d", time.Now().Unix())

		job := &batchv1.Job{
			ObjectMeta: metav1.ObjectMeta{
				Name:      jobName,
				Namespace: config.Namespace,
				Labels: map[string]string{
					"app":            "kaniko-builder",
					"created-by":     "knative-lambda-test",
					"test-component": "kaniko",
				},
			},
			Spec: batchv1.JobSpec{
				BackoffLimit: aws.Int32(3),
				Template: corev1.PodTemplateSpec{
					ObjectMeta: metav1.ObjectMeta{
						Labels: map[string]string{
							"app":        "kaniko-builder",
							"created-by": "knative-lambda-test",
						},
					},
					Spec: corev1.PodSpec{
						RestartPolicy: corev1.RestartPolicyNever,
						Containers: []corev1.Container{
							{
								Name:  "kaniko",
								Image: "gcr.io/kaniko-project/executor:latest",
								Args: []string{
									"--context=tar://stdin",
									"--dockerfile=Dockerfile",
									"--destination=fake-registry/test:latest",
									"--no-push", // Don't actually push to avoid authentication issues
								},
								Stdin: true,
								Resources: corev1.ResourceRequirements{
									Requests: corev1.ResourceList{
										corev1.ResourceCPU:    resource.MustParse("100m"),
										corev1.ResourceMemory: resource.MustParse("256Mi"),
									},
									Limits: corev1.ResourceList{
										corev1.ResourceCPU:    resource.MustParse("500m"),
										corev1.ResourceMemory: resource.MustParse("512Mi"),
									},
								},
							},
						},
					},
				},
			},
		}

		// Deploy the job
		createdJob, err := clientset.BatchV1().Jobs(config.Namespace).Create(ctx, job, metav1.CreateOptions{})
		if err != nil {
			t.Fatalf("Failed to create job: %v", err)
		}

		t.Logf("Successfully created job %s in namespace %s", createdJob.Name, createdJob.Namespace)

		// Wait for job to start
		err = wait.PollImmediate(5*time.Second, 60*time.Second, func() (bool, error) {
			updatedJob, err := clientset.BatchV1().Jobs(config.Namespace).Get(ctx, jobName, metav1.GetOptions{})
			if err != nil {
				return false, err
			}

			// Check if job has started (has active pods or completed)
			return updatedJob.Status.Active > 0 || updatedJob.Status.Succeeded > 0 || updatedJob.Status.Failed > 0, nil
		})

		if err != nil {
			t.Logf("Warning: job may not have started within timeout: %v", err)
		} else {
			t.Logf("Job %s has started execution", jobName)
		}

		// Get final job status
		finalJob, err := clientset.BatchV1().Jobs(config.Namespace).Get(ctx, jobName, metav1.GetOptions{})
		if err != nil {
			t.Logf("Warning: failed to get final job status: %v", err)
		} else {
			t.Logf("Final job status - Active: %d, Succeeded: %d, Failed: %d",
				finalJob.Status.Active, finalJob.Status.Succeeded, finalJob.Status.Failed)
		}
	})
}

// TestEKSDeployConfigMap tests deploying a ConfigMap to EKS
func TestEKSDeployConfigMap(t *testing.T) {
	if skipEKSTests(t) {
		return
	}

	config := getEKSTestConfig()

	kubeConfig, err := getEKSKubernetesConfig(config.ClusterName, config.Region)
	if err != nil {
		t.Fatalf("Failed to get EKS Kubernetes config: %v", err)
	}

	clientset, err := kubernetes.NewForConfig(kubeConfig)
	if err != nil {
		t.Fatalf("Failed to create Kubernetes clientset: %v", err)
	}

	ctx, cancel := context.WithTimeout(context.Background(), config.Timeout)
	defer cancel()

	// Ensure test namespace exists
	err = ensureNamespace(ctx, clientset, config.Namespace)
	if err != nil {
		t.Fatalf("Failed to ensure namespace: %v", err)
	}

	// Cleanup function
	cleanup := func() {
		if !config.SkipCleanup {
			cleanupCtx, cleanupCancel := context.WithTimeout(context.Background(), 30*time.Second)
			defer cleanupCancel()
			if err := cleanupTestResources(cleanupCtx, clientset, config.Namespace); err != nil {
				t.Logf("Warning: cleanup failed: %v", err)
			}
		}
	}
	defer cleanup()

	t.Run("deploy and verify configmap", func(t *testing.T) {
		configMapName := fmt.Sprintf("test-config-%d", time.Now().Unix())

		configMap := &corev1.ConfigMap{
			ObjectMeta: metav1.ObjectMeta{
				Name:      configMapName,
				Namespace: config.Namespace,
				Labels: map[string]string{
					"app":        "knative-lambda-test",
					"created-by": "knative-lambda-test",
					"test-type":  "integration",
				},
			},
			Data: map[string]string{
				"config.yaml": `
app:
  name: knative-lambda-test
  version: 1.0.0
  debug: true
parser:
  timeout: 30s
  max_retries: 3
`,
				"parser.json": `{
  "thirdPartyId": "test-party",
  "parserId": "test-parser",
  "region": "us-east-1"
}`,
			},
		}

		// Create the ConfigMap
		createdConfigMap, err := clientset.CoreV1().ConfigMaps(config.Namespace).Create(ctx, configMap, metav1.CreateOptions{})
		if err != nil {
			t.Fatalf("Failed to create ConfigMap: %v", err)
		}

		t.Logf("Successfully created ConfigMap %s", createdConfigMap.Name)

		// Verify the ConfigMap was created correctly
		retrievedConfigMap, err := clientset.CoreV1().ConfigMaps(config.Namespace).Get(ctx, configMapName, metav1.GetOptions{})
		if err != nil {
			t.Fatalf("Failed to retrieve ConfigMap: %v", err)
		}

		// Verify data
		if len(retrievedConfigMap.Data) != 2 {
			t.Errorf("Expected 2 data entries, got %d", len(retrievedConfigMap.Data))
		}

		if _, exists := retrievedConfigMap.Data["config.yaml"]; !exists {
			t.Error("config.yaml data not found in ConfigMap")
		}

		if _, exists := retrievedConfigMap.Data["parser.json"]; !exists {
			t.Error("parser.json data not found in ConfigMap")
		}

		// Verify labels
		if retrievedConfigMap.Labels["app"] != "knative-lambda-test" {
			t.Errorf("Expected app label to be 'knative-lambda-test', got %s", retrievedConfigMap.Labels["app"])
		}

		t.Logf("ConfigMap verification completed successfully")
	})
}

// TestEKSResourceTemplates tests deploying resources from templates to EKS
func TestEKSResourceTemplates(t *testing.T) {
	if skipEKSTests(t) {
		return
	}

	config := getEKSTestConfig()

	kubeConfig, err := getEKSKubernetesConfig(config.ClusterName, config.Region)
	if err != nil {
		t.Fatalf("Failed to get EKS Kubernetes config: %v", err)
	}

	ctx, cancel := context.WithTimeout(context.Background(), config.Timeout)
	defer cancel()

	// Cleanup function
	cleanup := func() {
		if !config.SkipCleanup {
			cleanupCtx, cleanupCancel := context.WithTimeout(context.Background(), 30*time.Second)
			defer cleanupCancel()

			// Apply cleanup using the same function we use for deployment
			cleanupYaml := `apiVersion: v1
kind: ConfigMap
metadata:
  name: test-template-config
  namespace: ` + config.Namespace + `
`
			// Try to delete the resource (this will fail if it doesn't exist, which is fine)
			_ = applyUnstructuredResource(cleanupCtx, kubeConfig, cleanupYaml, config.Namespace)
		}
	}
	defer cleanup()

	t.Run("deploy from yaml template", func(t *testing.T) {
		// Create YAML content for a ConfigMap
		yamlContent := fmt.Sprintf(`apiVersion: v1
kind: ConfigMap
metadata:
  name: test-template-config-%d
  namespace: %s
  labels:
    app: knative-lambda-test
    created-by: knative-lambda-test
    deployment-method: template
data:
  template.test: "true"
  timestamp: "%d"
  cluster: "%s"
  region: "%s"
`, time.Now().Unix(), config.Namespace, time.Now().Unix(), config.ClusterName, config.Region)

		// Apply the resource using our existing function
		err := applyUnstructuredResource(ctx, kubeConfig, yamlContent, config.Namespace)
		if err != nil {
			t.Fatalf("Failed to apply YAML template: %v", err)
		}

		t.Logf("Successfully applied YAML template to EKS cluster")
	})
}

// TestEKSServiceAccount tests EKS service account functionality
func TestEKSServiceAccount(t *testing.T) {
	if skipEKSTests(t) {
		return
	}

	config := getEKSTestConfig()

	kubeConfig, err := getEKSKubernetesConfig(config.ClusterName, config.Region)
	if err != nil {
		t.Fatalf("Failed to get EKS Kubernetes config: %v", err)
	}

	clientset, err := kubernetes.NewForConfig(kubeConfig)
	if err != nil {
		t.Fatalf("Failed to create Kubernetes clientset: %v", err)
	}

	ctx, cancel := context.WithTimeout(context.Background(), config.Timeout)
	defer cancel()

	// Ensure test namespace exists
	err = ensureNamespace(ctx, clientset, config.Namespace)
	if err != nil {
		t.Fatalf("Failed to ensure namespace: %v", err)
	}

	t.Run("verify service account exists", func(t *testing.T) {
		// Check if the knative-lambda-builder service account exists
		serviceAccountName := "knative-lambda-builder"

		// First try to get it from the test namespace
		_, err := clientset.CoreV1().ServiceAccounts(config.Namespace).Get(ctx, serviceAccountName, metav1.GetOptions{})
		if err != nil {
			t.Logf("Service account %s not found in test namespace, this is expected for tests", serviceAccountName)
		} else {
			t.Logf("Service account %s found in test namespace", serviceAccountName)
		}

		// List all service accounts in the namespace for debugging
		serviceAccounts, err := clientset.CoreV1().ServiceAccounts(config.Namespace).List(ctx, metav1.ListOptions{})
		if err != nil {
			t.Logf("Failed to list service accounts: %v", err)
		} else {
			t.Logf("Found %d service accounts in namespace %s", len(serviceAccounts.Items), config.Namespace)
			for _, sa := range serviceAccounts.Items {
				t.Logf("  - %s", sa.Name)
			}
		}
	})
}

// TestGetKubernetesConfig tests the getKubernetesConfig function
func TestGetKubernetesConfig(t *testing.T) {
	// Save original environment
	originalKubeconfig := os.Getenv("KUBECONFIG")
	defer func() {
		if originalKubeconfig != "" {
			os.Setenv("KUBECONFIG", originalKubeconfig)
		} else {
			os.Unsetenv("KUBECONFIG")
		}
	}()

	t.Run("with KUBECONFIG environment variable", func(t *testing.T) {
		// Create a temporary kubeconfig file
		tempDir, err := os.MkdirTemp("", "test-kubeconfig")
		if err != nil {
			t.Fatalf("Failed to create temp dir: %v", err)
		}
		defer os.RemoveAll(tempDir)

		kubeconfigPath := filepath.Join(tempDir, "config")
		kubeconfigContent := `apiVersion: v1
kind: Config
current-context: test-context
contexts:
- context:
    cluster: test-cluster
    user: test-user
  name: test-context
clusters:
- cluster:
    server: https://kubernetes.example.com
  name: test-cluster
users:
- name: test-user
  user:
    token: test-token`

		if err := os.WriteFile(kubeconfigPath, []byte(kubeconfigContent), 0644); err != nil {
			t.Fatalf("Failed to write kubeconfig file: %v", err)
		}

		os.Setenv("KUBECONFIG", kubeconfigPath)

		config, err := getKubernetesConfig()
		if err != nil {
			t.Errorf("getKubernetesConfig() error = %v", err)
			return
		}

		if config == nil {
			t.Error("getKubernetesConfig() returned nil config")
			return
		}

		if config.Host != "https://kubernetes.example.com" {
			t.Errorf("Config host = %v, want %v", config.Host, "https://kubernetes.example.com")
		}

		if config.Timeout.Seconds() != 60 {
			t.Errorf("Config timeout = %v, want %v seconds", config.Timeout.Seconds(), 60)
		}
	})

	t.Run("with invalid kubeconfig path", func(t *testing.T) {
		os.Setenv("KUBECONFIG", "/non/existent/path")

		_, err := getKubernetesConfig()
		if err == nil {
			t.Error("getKubernetesConfig() should return error for invalid kubeconfig path")
		}
		if !strings.Contains(err.Error(), "failed to build config from kubeconfig") {
			t.Errorf("Expected kubeconfig error, got: %v", err)
		}
	})

	t.Run("without KUBECONFIG environment variable", func(t *testing.T) {
		os.Unsetenv("KUBECONFIG")

		// This test will likely fail in CI/CD environments without a cluster
		// but it tests the fallback logic
		_, err := getKubernetesConfig()

		// We expect an error in most test environments since we won't have
		// either in-cluster config or a valid kubeconfig
		if err == nil {
			t.Log("getKubernetesConfig() succeeded - likely running in cluster or with valid kubeconfig")
		} else {
			t.Logf("getKubernetesConfig() failed as expected in test environment: %v", err)
		}
	})
}

// TestApplyKubernetesResource tests the applyKubernetesResource function
func TestApplyKubernetesResource(t *testing.T) {
	t.Run("valid yaml content", func(t *testing.T) {
		yamlContent := `apiVersion: v1
kind: ConfigMap
metadata:
  name: test-config
  namespace: default
data:
  key: value`

		// This test will likely fail without a real cluster connection
		// but it tests the YAML parsing logic
		err := applyKubernetesResource(yamlContent)

		// In a test environment without cluster access, we expect this to fail
		// with a connection error, not a parsing error
		if err != nil {
			// Check that it's not a YAML parsing error
			if strings.Contains(err.Error(), "failed to unmarshal YAML") {
				t.Errorf("applyKubernetesResource() failed with YAML parsing error: %v", err)
			} else {
				t.Logf("applyKubernetesResource() failed as expected without cluster: %v", err)
			}
		} else {
			t.Log("applyKubernetesResource() succeeded - likely running with valid cluster access")
		}
	})

	t.Run("invalid yaml content", func(t *testing.T) {
		invalidYaml := `this is not: valid: yaml:
  - with multiple: colons: in wrong: places:`

		err := applyKubernetesResource(invalidYaml)
		if err == nil {
			t.Error("applyKubernetesResource() should return error for invalid YAML")
		}
		if !strings.Contains(err.Error(), "failed to decode resource YAML") {
			t.Errorf("Expected YAML parsing error, got: %v", err)
		}
	})

	t.Run("empty yaml content", func(t *testing.T) {
		err := applyKubernetesResource("")
		if err == nil {
			t.Error("applyKubernetesResource() should return error for empty YAML")
		}
	})
}

// TestApplyUnstructuredResource tests the applyUnstructuredResource function
func TestApplyUnstructuredResource(t *testing.T) {
	// Create a mock REST config
	config := &rest.Config{
		Host: "https://kubernetes.example.com",
	}

	t.Run("valid unstructured resource", func(t *testing.T) {
		yamlContent := `apiVersion: v1
kind: ConfigMap
metadata:
  name: test-config
  namespace: default
data:
  key: value`

		ctx := context.Background()

		// This will fail without a real cluster, but tests the parsing logic
		err := applyUnstructuredResource(ctx, config, yamlContent, "default")

		if err != nil {
			// Should fail with connection error, not parsing error
			if strings.Contains(err.Error(), "failed to unmarshal YAML") {
				t.Errorf("applyUnstructuredResource() failed with parsing error: %v", err)
			} else {
				t.Logf("applyUnstructuredResource() failed as expected without cluster: %v", err)
			}
		}
	})

	t.Run("invalid yaml content", func(t *testing.T) {
		invalidYaml := `invalid yaml content`
		ctx := context.Background()

		err := applyUnstructuredResource(ctx, config, invalidYaml, "default")
		if err == nil {
			t.Error("applyUnstructuredResource() should return error for invalid YAML")
		}
		if !strings.Contains(err.Error(), "failed to unmarshal resource JSON") {
			t.Errorf("Expected YAML parsing error, got: %v", err)
		}
	})
}

// TestKubernetesResourceCreation tests creating Kubernetes resources from templates
func TestKubernetesResourceCreation(t *testing.T) {
	t.Run("create job from template", func(t *testing.T) {
		// Create a temporary directory for the template
		tempDir, err := os.MkdirTemp("", "test-k8s-job")
		if err != nil {
			t.Fatalf("Failed to create temp dir: %v", err)
		}
		defer os.RemoveAll(tempDir)

		// Create a job template
		jobTemplate := `apiVersion: batch/v1
kind: Job
metadata:
  name: {{.Name}}
  namespace: {{.Namespace}}
  labels:
    app: kaniko-builder
    thirdPartyId: {{.ThirdPartyId}}
    parserId: {{.ParserId}}
spec:
  backoffLimit: 3
  template:
    metadata:
      labels:
        app: kaniko-builder
    spec:
      serviceAccountName: {{.ServiceAccount}}
      containers:
      - name: kaniko
        image: gcr.io/kaniko-project/executor:latest
        args:
        - "--context={{.Context}}"
        - "--dockerfile={{.Dockerfile}}"
        - "--destination={{.ImageTag}}"
        env:
        - name: AWS_DEFAULT_REGION
          value: {{.Region}}
      restartPolicy: Never`

		templatePath := filepath.Join(tempDir, "job.yaml.tpl")
		if err := os.WriteFile(templatePath, []byte(jobTemplate), 0644); err != nil {
			t.Fatalf("Failed to write job template: %v", err)
		}

		// Template data
		data := struct {
			Name           string
			Namespace      string
			ThirdPartyId   string
			ParserId       string
			ServiceAccount string
			Context        string
			Dockerfile     string
			ImageTag       string
			Region         string
		}{
			Name:           "test-job-12345",
			Namespace:      "knative-lambda",
			ThirdPartyId:   "test-party",
			ParserId:       "test-parser",
			ServiceAccount: "knative-lambda-builder",
			Context:        "s3://test-bucket/context.tar.gz",
			Dockerfile:     "Dockerfile",
			ImageTag:       "123456789012.dkr.ecr.us-east-1.amazonaws.com/test:latest",
			Region:         "us-east-1",
		}

		// Parse template into Job
		var job batchv1.Job
		err = parseTemplate(templatePath, data, &job)
		if err != nil {
			t.Fatalf("Failed to parse job template: %v", err)
		}

		// Validate the created job
		if job.ObjectMeta.Name != "test-job-12345" {
			t.Errorf("Job name = %v, want %v", job.ObjectMeta.Name, "test-job-12345")
		}
		if job.ObjectMeta.Namespace != "knative-lambda" {
			t.Errorf("Job namespace = %v, want %v", job.ObjectMeta.Namespace, "knative-lambda")
		}
		if job.Spec.Template.Spec.ServiceAccountName != "knative-lambda-builder" {
			t.Errorf("ServiceAccount = %v, want %v", job.Spec.Template.Spec.ServiceAccountName, "knative-lambda-builder")
		}

		// Validate labels
		if job.ObjectMeta.Labels["app"] != "kaniko-builder" {
			t.Errorf("App label = %v, want %v", job.ObjectMeta.Labels["app"], "kaniko-builder")
		}
		if job.ObjectMeta.Labels["thirdPartyId"] != "test-party" {
			t.Errorf("ThirdPartyId label = %v, want %v", job.ObjectMeta.Labels["thirdPartyId"], "test-party")
		}
		if job.ObjectMeta.Labels["parserId"] != "test-parser" {
			t.Errorf("ParserId label = %v, want %v", job.ObjectMeta.Labels["parserId"], "test-parser")
		}

		// Validate container configuration
		if len(job.Spec.Template.Spec.Containers) != 1 {
			t.Fatalf("Expected 1 container, got %d", len(job.Spec.Template.Spec.Containers))
		}

		container := job.Spec.Template.Spec.Containers[0]
		if container.Name != "kaniko" {
			t.Errorf("Container name = %v, want %v", container.Name, "kaniko")
		}
		if container.Image != "gcr.io/kaniko-project/executor:latest" {
			t.Errorf("Container image = %v, want %v", container.Image, "gcr.io/kaniko-project/executor:latest")
		}

		// Validate environment variables
		foundRegion := false
		for _, env := range container.Env {
			if env.Name == "AWS_DEFAULT_REGION" && env.Value == "us-east-1" {
				foundRegion = true
				break
			}
		}
		if !foundRegion {
			t.Error("AWS_DEFAULT_REGION environment variable not found or incorrect")
		}

		// Validate restart policy
		if job.Spec.Template.Spec.RestartPolicy != corev1.RestartPolicyNever {
			t.Errorf("RestartPolicy = %v, want %v", job.Spec.Template.Spec.RestartPolicy, corev1.RestartPolicyNever)
		}
	})

	t.Run("create service from template", func(t *testing.T) {
		tempDir, err := os.MkdirTemp("", "test-k8s-service")
		if err != nil {
			t.Fatalf("Failed to create temp dir: %v", err)
		}
		defer os.RemoveAll(tempDir)

		serviceTemplate := `apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: parser-{{.ThirdPartyId}}-{{.ParserId}}
  namespace: knative-lambda
  labels:
    app: parser
    thirdPartyId: {{.ThirdPartyId}}
    parserId: {{.ParserId}}
spec:
  template:
    metadata:
      labels:
        app: parser
    spec:
      containers:
      - image: {{.Image}}
        env:
        - name: PARSER_ID
          value: "{{.ParserId}}"
        - name: THIRD_PARTY_ID
          value: "{{.ThirdPartyId}}"
        ports:
        - containerPort: 8080
        resources:
          limits:
            cpu: 1000m
            memory: 512Mi
          requests:
            cpu: 100m
            memory: 128Mi`

		templatePath := filepath.Join(tempDir, "service.yaml.tpl")
		if err := os.WriteFile(templatePath, []byte(serviceTemplate), 0644); err != nil {
			t.Fatalf("Failed to write service template: %v", err)
		}

		data := ServiceTemplateData{
			ThirdPartyId: "test-party",
			ParserId:     "test-parser",
			Image:        "123456789012.dkr.ecr.us-east-1.amazonaws.com/test:latest",
		}

		// Parse template into unstructured for more flexible validation
		var service unstructured.Unstructured
		err = parseTemplate(templatePath, data, &service)
		if err != nil {
			t.Fatalf("Failed to parse service template: %v", err)
		}

		// Validate the created service
		if service.GetName() != "parser-test-party-test-parser" {
			t.Errorf("Service name = %v, want %v", service.GetName(), "parser-test-party-test-parser")
		}
		if service.GetNamespace() != "knative-lambda" {
			t.Errorf("Service namespace = %v, want %v", service.GetNamespace(), "knative-lambda")
		}

		// Validate GVK
		gvk := service.GroupVersionKind()
		expectedGVK := schema.GroupVersionKind{
			Group:   "serving.knative.dev",
			Version: "v1",
			Kind:    "Service",
		}
		if gvk != expectedGVK {
			t.Errorf("Service GVK = %v, want %v", gvk, expectedGVK)
		}

		// Validate labels
		labels := service.GetLabels()
		if labels["app"] != "parser" {
			t.Errorf("App label = %v, want %v", labels["app"], "parser")
		}
		if labels["thirdPartyId"] != "test-party" {
			t.Errorf("ThirdPartyId label = %v, want %v", labels["thirdPartyId"], "test-party")
		}
		if labels["parserId"] != "test-parser" {
			t.Errorf("ParserId label = %v, want %v", labels["parserId"], "test-parser")
		}
	})
}

// TestNamespaceValidation tests namespace validation
func TestNamespaceValidation(t *testing.T) {
	tests := []struct {
		name      string
		namespace string
		valid     bool
	}{
		{
			name:      "valid namespace",
			namespace: "knative-lambda",
			valid:     true,
		},
		{
			name:      "default namespace",
			namespace: "default",
			valid:     true,
		},
		{
			name:      "kube-system namespace",
			namespace: "kube-system",
			valid:     true,
		},
		{
			name:      "namespace with numbers",
			namespace: "test-namespace-123",
			valid:     true,
		},
		{
			name:      "empty namespace",
			namespace: "",
			valid:     false,
		},
		{
			name:      "namespace with invalid characters",
			namespace: "Test_Namespace",
			valid:     false,
		},
		{
			name:      "namespace too long",
			namespace: strings.Repeat("a", 64), // Kubernetes namespace names must be < 64 characters
			valid:     false,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			// Simple validation logic (this could be expanded)
			valid := validateNamespace(tt.namespace)
			if valid != tt.valid {
				t.Errorf("validateNamespace(%v) = %v, want %v", tt.namespace, valid, tt.valid)
			}
		})
	}
}

// validateNamespace is a helper function for namespace validation
func validateNamespace(namespace string) bool {
	if namespace == "" {
		return false
	}
	if len(namespace) >= 64 {
		return false
	}
	// Check for invalid characters (simplified check)
	for _, char := range namespace {
		if char >= 'A' && char <= 'Z' {
			return false // uppercase not allowed
		}
		if char == '_' {
			return false // underscore not allowed
		}
	}
	return true
}

// TestResourceLabeling tests that resources are properly labeled
func TestResourceLabeling(t *testing.T) {
	buildEvent := MockBuildEvent()

	t.Run("job labels", func(t *testing.T) {
		labels := map[string]string{
			"app":          "kaniko-builder",
			"thirdPartyId": buildEvent.ThirdPartyId,
			"parserId":     buildEvent.ParserId,
			"component":    "builder",
		}

		// Verify all expected labels are present
		expectedLabels := []string{"app", "thirdPartyId", "parserId", "component"}
		for _, label := range expectedLabels {
			if _, exists := labels[label]; !exists {
				t.Errorf("Expected label %s not found in labels", label)
			}
		}

		// Verify label values
		if labels["thirdPartyId"] != buildEvent.ThirdPartyId {
			t.Errorf("ThirdPartyId label = %v, want %v", labels["thirdPartyId"], buildEvent.ThirdPartyId)
		}
		if labels["parserId"] != buildEvent.ParserId {
			t.Errorf("ParserId label = %v, want %v", labels["parserId"], buildEvent.ParserId)
		}
	})

	t.Run("service labels", func(t *testing.T) {
		labels := map[string]string{
			"app":          "parser",
			"thirdPartyId": buildEvent.ThirdPartyId,
			"parserId":     buildEvent.ParserId,
			"component":    "service",
		}

		// Verify all expected labels are present
		expectedLabels := []string{"app", "thirdPartyId", "parserId", "component"}
		for _, label := range expectedLabels {
			if _, exists := labels[label]; !exists {
				t.Errorf("Expected label %s not found in labels", label)
			}
		}
	})
}

// BenchmarkKubernetesOperations benchmarks Kubernetes operations
func BenchmarkKubernetesOperations(b *testing.B) {
	b.Run("ParseJobTemplate", func(b *testing.B) {
		tempDir, err := os.MkdirTemp("", "benchmark-k8s")
		if err != nil {
			b.Fatalf("Failed to create temp dir: %v", err)
		}
		defer os.RemoveAll(tempDir)

		jobTemplate := `apiVersion: batch/v1
kind: Job
metadata:
  name: {{.Name}}
  namespace: knative-lambda
spec:
  template:
    spec:
      containers:
      - name: kaniko
        image: gcr.io/kaniko-project/executor:latest
        args:
        - "--context={{.Context}}"
      restartPolicy: Never`

		templatePath := filepath.Join(tempDir, "job.yaml.tpl")
		if err := os.WriteFile(templatePath, []byte(jobTemplate), 0644); err != nil {
			b.Fatalf("Failed to write template: %v", err)
		}

		data := JobTemplateData{
			Name:    "benchmark-job",
			Context: "s3://bucket/context.tar.gz",
		}

		b.ResetTimer()
		for i := 0; i < b.N; i++ {
			var job batchv1.Job
			parseTemplate(templatePath, data, &job)
		}
	})
}
